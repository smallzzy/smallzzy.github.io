---
layout: post
title: 
date: 2021-03-04 15:39
category: 
author: 
tags: []
summary: 
---

## softmax

generates classification probability

softmax = exp(x_i) / sum(exp(x_i))

### NLLLoss

negative log likelihood loss 

lower loss for higher correct probability 

L = -log(probability of correct classification)

### CrossEntropyLoss

Softmax + NLLLoss

## LogSumExp

RealSoftMax, softplus

approximate max function

LSE(x_i) = log( sum(exp(x_i)) )

max(x_i) < LSE(x_i) <= max(x_i) + log(n)

log semi-ring?

## KLDivLoss

different between two distribution
